# ğŸš€ HHO-Based Fusion of YOLOv5 & YOLOv8 for Enhanced Locust Detection
ğŸ” A deep learningâ€“based object detection model for locust identification using an HHO-optimized fusion of YOLOv5 and YOLOv8.

## ğŸ“Œ Project Overview
This is the official repository for my research work:

"HHO-Based Fusion of YOLOv5 and YOLOv8 for Enhanced Locust Detection" (DOI: 10.5281/zenodo.14996737)

This study proposes a Harris Hawks Optimization (HHO)â€“based fusion framework that combines the strengths of YOLOv5 and YOLOv8 for accurate and efficient locust identification.
The dataset has been curated, annotated, and augmented specifically for this task.
This repository presents the implementation, fusion process, and performance evaluation of the proposed HHO-based fused YOLOv5â€“YOLOv8 model for real-world locust identification in smart farming applications. The study was conducted on:

1ï¸âƒ£ A curated dataset specifically prepared for locust detection.

2ï¸âƒ£ An augmented version of the dataset, where various augmentation techniques were applied to enhance model robustness.

3ï¸âƒ£ Labels are in YOLO format.

## ğŸ”¥ Key Findings:
â—† The HHO-based fused model achieved a higher Mean IoU and better detection accuracy compared to individual YOLO models.

â—† The fusion reduced false positives and improved overall model robustness under varied lighting and environmental conditions.

â—† The fusion strategy effectively leveraged YOLOv5â€™s localization precision and YOLOv8â€™s generalization capability.

## âœ… Features
â˜… YOLOv5 + YOLOv8 fusion using Harris Hawks Optimization (HHO)

â˜… Curated and augmented dataset for locust detection

â˜… Training and inference scripts included

â˜… Fusion and evaluation scripts for HHO-based ensemble

â˜… Supports Google Colab for easy execution

## ğŸ“ Dataset & Model Files
ğŸ”¹ Code includes:

YOLOv5 and YOLOv8 base training scripts

HHO-based fusion implementation (fusion_hho.ipynb)

Inference and visualization utilities


ğŸ”¹ Dataset is structured like this
```
locust_detection
â”œâ”€â”€ images
â”‚ â”œâ”€â”€ train
â”‚ â”‚ â”œâ”€â”€ img_001.jpg
â”‚ â”‚ â”œâ”€â”€ img_002.jpg
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”œâ”€â”€ val
â”‚ â”‚ â”œâ”€â”€ img_101.jpg
â”‚ â”‚ â”œâ”€â”€ img_102.jpg
â”‚ â”‚ â””â”€â”€ ...
â””â”€â”€ labels
â”œâ”€â”€ train
â”‚ â”œâ”€â”€ img_001.txt
â”‚ â”œâ”€â”€ img_002.txt
â”‚ â””â”€â”€ ...
â”œâ”€â”€ val
â”‚ â”œâ”€â”€ img_101.txt
â”‚ â”œâ”€â”€ img_102.txt
â”‚ â””â”€â”€ ...
```
## ğŸ¯ Augmentation Techniques Applied

The following augmentation techniques were applied to improve model diversity and robustness:

ğŸ”¹ Horizontal & Vertical Flip

ğŸ”¹ Brightness and Contrast Adjustment

ğŸ”¹ Rotation and Scaling

ğŸ”¹ Gaussian Blur

ğŸ”¹ HSV Modification

ğŸ”¹ Color Shifting

ğŸ”¹ Cropping

ğŸ’¡ Augmentation script: augmentation.ipynb

### **Applied Augmentation Techniques**
![Augmentation](Results/augmentation.jpg)

## ğŸš€ Installation & Setup


1ï¸âƒ£ Clone the Repository

git clone https://github.com/yourusername/locust-fusion-hho.git  
cd locust-fusion-hho


2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

ğŸ‘‰ If using Google Colab, run:

!pip install -r requirements.txt


3ï¸âƒ£ Download the Dataset
Since the dataset is hosted on Zenodo, download it manually from:
ğŸ”— Dataset DOI: 10.5281/zenodo.14964987

Unzip and place it in the correct directory (datasets/).

4ï¸âƒ£ Mount Google Drive (if using Colab)
from google.colab import drive
drive.mount('/content/drive')



## ğŸ”§ Training 

We trained and evaluated:

â—† YOLOv5 baseline

â—† YOLOv8 baseline

â—† Proposed HHO-based Fusion model

## âš¡ Training Commands

âœ” Train YOLOv5

!python train.py --img 640 --batch 16 --epochs 60 --data dataset.yaml --weights yolov5s.pt

âœ” Train YOLOv8

results = model.train(
    data='dataset.yaml',
    epochs=60,
    batch=16,
    imgsz=640
)

âœ” Perform HHO-Based Fusion


ğŸ† Results & Evaluation

â—† The fused YOLOv5â€“YOLOv8 model achieved Mean IoU: 0.614 with the lowest False Detection Rate among all models.

â—† The HHO optimization balanced model outputs to enhance reliability across test samples.

Performance Comparison

| Model                       | Mean IoU  | Precision | Recall   | F1 Score |
| --------------------------- | --------- | --------- | -------- | -------- |
| YOLOv5                      | 0.589     | 0.82      | 0.78     | 0.80     |
| YOLOv8                      | 0.607     | 0.84      | 0.81     | 0.82     |
| **HHO-Fused YOLOv5+YOLOv8** | **0.614** | **0.86**  | **0.84** | **0.85** |




## âš¡ Results showed that YOLOv8 outperformed YOLOv5 in detection accuracy especially after augmentation.



## ğŸ“¸ Visual Comparison of Results
Below are performance results:


ğŸ“¸ Sample Output

![Fused, Yolov8, Yolov5 Output](Results/detection.jpg)

ğŸ“œ Citation

If you use this dataset or model, please cite the following:

ğŸ”— Dataset DOI: 10.5281/zenodo.14964987

ğŸ”— Fusion Model DOI: 10.5281/zenodo.14996737

## ğŸ“œ Citation

If you use this dataset, please cite the Zenodo DOI:  
ğŸ”— DOI: [10.5281/zenodo.14964987](https://doi.org/10.5281/zenodo.14964987)  

```bibtex
@misc{vajpayee2025locust,
  author    = {Pooja Vajpayee and Kuldeep Kr. Yogi},
  title     = {Locust Images Dataset},
  year      = {2025},
  publisher = {Zenodo},
  doi       = {10.5281/zenodo.14964987},
  url       = {https://doi.org/10.5281/zenodo.14964987}
}
```



## ğŸ“„ License
ğŸ”¹ This project is licensed under the MIT License.

## ğŸ¤ Acknowledgments
Special thanks to Ultralytics for YOLO development.

## ğŸ“¬ Contact

For questions, reach out via poojavjpy@gmail.com or https://www.researchgate.net/profile/Pooja-Vajpayee-2/research

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.14996738.svg)](https://doi.org/10.5281/zenodo.14996738)


